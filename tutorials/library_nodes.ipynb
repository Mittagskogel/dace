{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library Nodes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`LibraryNode`s facilitate the abstraction of common operations, enabling easy reuse in different SDFGs and Data-Centric progrmas. This tutorial covers creating `LibraryNode`s with different implelementations (called *expansions* or `ExpandTransformation`s), and how to use them in SDFGs or Data-Centric programs."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this tutorial, we use as an example the SDDMM (sampled dense-dense matrix multiplication) operation:\n",
    "$$\\bm{D} = \\bm{A} \\odot \\left(\\bm{B} \\times \\bm{C}\\right)$$\n",
    "$\\bm{A}$ is a sparse matrix, while $\\bm{B}$ and $\\bm{C}$ are dense matrices. The ouput $\\bm{D}$ is the Hadamard (element-wise) product of $\\bm{A}$ and the matrix product of $\\bm{B}$ and $\\bm{C}$, and has the same sparsity pattern as $\\bm{A}$. Effectively, $\\bm{A}$ *samples* (or filters) the dense product $\\bm{B} \\times \\bm{C}$. Assuming $\\bm{A}$ is in CSR format, the SDDMM algorithm is as follows:\n",
    "\n",
    "```python\n",
    "# A (D) has shape (M, N) with nnz non-zero values\n",
    "# A_data (D_data) is the non-zero values of A (D)\n",
    "# A_indices (D_indices) is the column indices of A (D)\n",
    "# A_indptr (D_indptr) is the row pointers of A (D)\n",
    "# B has shape (M, K)\n",
    "# C has shape (K, N)\n",
    "D_data = np.zeros_like(A_data)\n",
    "D_indices = np.copy(A_indices)\n",
    "D_indptr = np.copy(A_indptr)\n",
    "for i in range(M):\n",
    "    for j in range(A_indptr[i], A_indptr[i + 1]):\n",
    "        for k in range(K):\n",
    "            D_data[j] += B[i, k] * C[k, A_indices[j]]\n",
    "        D_data[j] *= A_data[j]\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by creating a LibraryNode that represents the SDDMM operation. We create a class that inherits from `dace.sdfg.nodes.LibraryNode`, and we decorate it with `@dace.library.node`. The class must include an `implementations` dictionary, and an `defaul_implementation` string, which we will discuss later. The `LibraryNode`'s initialization method must call the initialization method of the super-class and pass the node's name, location, inputs, and outputs. The inputs and the outputs are the node's connector names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dace\n",
    "\n",
    "from dace import library\n",
    "from dace.sdfg import nodes\n",
    "from dace.transformation import ExpandTransformation\n",
    "from typing import Dict\n",
    "\n",
    "\n",
    "@library.node\n",
    "class MySDDMM(nodes.LibraryNode):\n",
    "\n",
    "    # We will fill those later\n",
    "    implementations: Dict[str, ExpandTransformation] = {}\n",
    "    default_implementation: str = None\n",
    "\n",
    "    def __init__(self, name, location=None):\n",
    "        super().__init__(name,\n",
    "                         location=location,\n",
    "                         inputs={'_a_data', '_a_indices', '_a_indptr', '_b', '_c'},\n",
    "                         outputs={'_d_data', '_d_indices', '_d_indptr'})\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `LibraryNode` can have different implemenetations (expansions), generic or specialized for specific architectures. These implementations can use the SDFG API but they can also be written as Data-Centric programs. We start by creating a *pure* expansion, which is an implementation that does not use any components, e.g., libraries, external to DaCe. We write this expansion as a Data-Centric Python program:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@library.expansion\n",
    "class MySDDMMPureExpansion(ExpandTransformation):\n",
    "\n",
    "    environments = []\n",
    "\n",
    "    @staticmethod\n",
    "    def expansion(node, state, sdfg):\n",
    "\n",
    "        # Find shapes and datatypes of inputs and outputs\n",
    "\n",
    "        # A matrix\n",
    "        a_indptr_name = list(state.in_edges_by_connector(node, '_a_indptr'))[0].data.data\n",
    "        a_indptr_arr = sdfg.arrays[a_indptr_name]\n",
    "        a_data_name = list(state.in_edges_by_connector(node, '_a_data'))[0].data.data\n",
    "        a_data_arr = sdfg.arrays[a_data_name]\n",
    "        a_rowsp1 = a_indptr_arr.shape[0]\n",
    "        a_nnz = a_data_arr.shape[0]\n",
    "        a_dtype = a_data_arr.dtype\n",
    "\n",
    "        # B matrix\n",
    "        b_name = list(state.in_edges_by_connector(node, '_b'))[0].data.data\n",
    "        b_arr = sdfg.arrays[b_name]\n",
    "        b_rows = b_arr.shape[0]\n",
    "        b_cols = b_arr.shape[1]\n",
    "        b_dtype = b_arr.dtype\n",
    "\n",
    "        # C matrix\n",
    "        c_name = list(state.in_edges_by_connector(node, '_c'))[0].data.data\n",
    "        c_arr = sdfg.arrays[c_name]\n",
    "        c_rows = c_arr.shape[0]\n",
    "        c_cols = c_arr.shape[1]\n",
    "        c_dtype = c_arr.dtype\n",
    "\n",
    "        # D matrix\n",
    "        # We assume that it has the same shape and datatype as A\n",
    "\n",
    "        @dace.program\n",
    "        def sddmm_pure(_a_data: a_dtype[a_nnz], _a_indices: dace.int32[a_nnz], _a_indptr: dace.int32[a_rowsp1],\n",
    "                       _b: b_dtype[b_rows, b_cols], _c: c_dtype[c_rows, c_cols],\n",
    "                       _d_data: a_dtype[a_nnz], _d_indices: dace.int32[a_nnz], _d_indptr: dace.int32[a_rowsp1]):\n",
    "\n",
    "            _d_data[:] = 0\n",
    "            _d_indices[:] = _a_indices\n",
    "            _d_indptr[:] = _a_indptr\n",
    "\n",
    "            for i in dace.map[0:a_rowsp1 - 1]:\n",
    "                for j in dace.map[_a_indptr[i]:_a_indptr[i + 1]]:\n",
    "                    for k in dace.map[0:b_cols]:\n",
    "                        _d_data[j] += _b[i, k] * _c[k, _a_indices[j]]\n",
    "                    _d_data[j] *= _a_data[j]\n",
    "\n",
    "        return sddmm_pure.to_sdfg()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To enable the above expansion, we add it to the `implementations` dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@library.node\n",
    "class MySDDMM(nodes.LibraryNode):\n",
    "\n",
    "    implementations: Dict[str, ExpandTransformation] = {'pure': MySDDMMPureExpansion}\n",
    "    default_implementation: str = None\n",
    "\n",
    "    def __init__(self, name, location=None):\n",
    "        super().__init__(name,\n",
    "                         location=location,\n",
    "                         inputs={'_a_data', '_a_indices', '_a_indptr', '_b', '_c'},\n",
    "                         outputs={'_d_data', '_d_indices', '_d_indptr'})\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that there is at least one expansion for the `LibraryNode`, we can use it in an SDFG like any other `CodeNode` or `Tasklet`. However, it is also possible to automate its use in Data-Centric Python programs. We us as an example the inference formula for a single-layer of the Vanilla Attention (VA) Graph Neural Network (GNN):\n",
    "$$\\bm{H}^\\prime = \\sigma\\left(\\bm{A} \\odot \\left(\\bm{H} \\times \\bm{H}^T\\right) \\times \\bm{H} \\times \\bm{W}\\right)$$\n",
    "We implement the above formula as a Data-Centric Python program:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# A is N x N, H is N x K0, W is K0 x K1, H' is N x K1\n",
    "N, K0, K1, NNZ = (dace.symbol(s) for s in ('N', 'K0', 'K1', 'NNZ'))\n",
    "\n",
    "@dace.program\n",
    "def va_inference_layer(A_data: dace.float32[NNZ], A_indices: dace.int32[NNZ], A_indptr: dace.int32[N + 1],\n",
    "                       H: dace.float32[N, K0],\n",
    "                       W: dace.float32[K0, K1],\n",
    "                       H_prime: dace.float32[N, K1]):\n",
    "    \n",
    "    # S = A \\odot (H \\times H^T)\n",
    "    # S_data = np.empty_like(A_data)\n",
    "    # S_indices = np.empty_like(A_indices)\n",
    "    # S_indptr = np.empty_like(A_indptr)\n",
    "    # dace.sddmm_op(A_data, A_indices, A_indptr, W, H, np.transpose(H), S_data, S_indices, S_indptr)\n",
    "    S_data, S_indices, S_indptr = dace.sddmm_op(A_data, A_indices, A_indptr, H, np.transpose(H))\n",
    "\n",
    "    H_prime[:] = np.maximum(0, dace.csrmm_op(S_data, S_indices, S_indptr, H) @ W)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to convert the above program to SDFG, we need to define `SDDMM_op` and `CSRMM_op`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dace.frontend.common import op_repository \n",
    "\n",
    "\n",
    "@op_repository.replaces('dace.sddmm_op')\n",
    "def sddmm_libnode(pv: 'ProgramVisitor',\n",
    "                  sdfg: dace.SDFG,\n",
    "                  state: dace.SDFGState,\n",
    "                  A_data: str,\n",
    "                  A_indices: str,\n",
    "                  A_indptr: str,\n",
    "                  B: str,\n",
    "                  C: str):\n",
    "    # Input access nodes\n",
    "    A_data_acc, A_indices_acc, A_indptr_acc, B_acc, C_acc = (\n",
    "        state.add_access(n) for n in (A_data, A_indices, A_indptr, B, C))\n",
    "    # Output D\n",
    "    A_data_arr = sdfg.arrays[A_data]\n",
    "    A_indices_arr = sdfg.arrays[A_indices]\n",
    "    A_indptr_arr = sdfg.arrays[A_indptr]\n",
    "    D_data, D_data_arr = sdfg.add_temp_transient_like(A_data_arr)\n",
    "    D_indices, D_indices_arr = sdfg.add_temp_transient_like(A_indices_arr)\n",
    "    D_indptr, D_indptr_arr = sdfg.add_temp_transient_like(A_indptr_arr)\n",
    "    D_data_acc, D_indices_acc, D_indptr_acc = (state.add_access(n) for n in (D_data, D_indices, D_indptr))\n",
    "\n",
    "    libnode = MySDDMM('sddmm')\n",
    "    state.add_node(libnode)\n",
    "\n",
    "    # Connect nodes\n",
    "    state.add_edge(A_indptr_acc, None, libnode, '_a_indptr', dace.Memlet(A_indptr))\n",
    "    state.add_edge(A_indices_acc, None, libnode, '_a_indices', dace.Memlet(A_indices))\n",
    "    state.add_edge(A_data_acc, None, libnode, '_a_data', dace.Memlet(A_data))\n",
    "    state.add_edge(B_acc, None, libnode, '_b', dace.Memlet(B))\n",
    "    state.add_edge(C_acc, None, libnode, '_c', dace.Memlet(C))\n",
    "    state.add_edge(libnode, '_d_data', D_data_acc, None, dace.Memlet(D_data))\n",
    "    state.add_edge(libnode, '_d_indices', D_indices_acc, None, dace.Memlet(D_indices))\n",
    "    state.add_edge(libnode, '_d_indptr', D_indptr_acc, None, dace.Memlet(D_indptr))\n",
    "\n",
    "    return [D_data, D_indices, D_indptr]\n",
    "\n",
    "\n",
    "@op_repository.replaces('dace.csrmm_op')\n",
    "def csrmm_libnode(pv: 'ProgramVisitor',\n",
    "                  sdfg: dace.SDFG,\n",
    "                  state: dace.SDFGState,\n",
    "                  A_data: str,\n",
    "                  A_indices: str,\n",
    "                  A_indptr: str,\n",
    "                  B: str):\n",
    "    # Input access nodes\n",
    "    A_data_acc, A_indices_acc, A_indptr_acc, B_acc = (state.add_access(n) for n in (A_data, A_indices, A_indptr, B))\n",
    "    # Output C\n",
    "    A_indptr_arr = sdfg.arrays[A_indptr]\n",
    "    rows = A_indptr_arr.shape[0] - 1\n",
    "    cols = sdfg.arrays[B].shape[1]\n",
    "    A_data_arr = sdfg.arrays[A_data]\n",
    "    dtype = A_data_arr.dtype\n",
    "    C, C_arr = sdfg.add_temp_transient([rows, cols], dtype)\n",
    "    C_acc = state.add_write(C)\n",
    "\n",
    "    from dace.libraries.sparse import CSRMM\n",
    "    libnode = CSRMM('csrmm')\n",
    "    state.add_node(libnode)\n",
    "\n",
    "    # Connect nodes\n",
    "    state.add_edge(A_indptr_acc, None, libnode, '_a_rows', dace.Memlet(A_indptr))\n",
    "    state.add_edge(A_indices_acc, None, libnode, '_a_cols', dace.Memlet(A_indices))\n",
    "    state.add_edge(A_data_acc, None, libnode, '_a_vals', dace.Memlet(A_data))\n",
    "    state.add_edge(B_acc, None, libnode, '_b', dace.Memlet(B))\n",
    "    state.add_edge(libnode, '_c', C_acc, None, dace.Memlet(C))\n",
    "\n",
    "    return [C]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdfg = va_inference_layer.to_sdfg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'663bc3186b54f9811d87ff2ae3ec4f58847e7efad341b9672d2e1c3fc6c9ce0c'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdfg.save('sddmm_tutorial.sdfg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311-dace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f4365af6226d83ec02cf1620d431f52c426cf97622e40406a6477f8a55cb5e80"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
